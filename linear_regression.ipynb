{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection._split import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = [1,    2,        3,           4, 5,                  6, 100]\n",
    "#y = [0.99, 2.000001, 3.020000011, 4, 4.9999999999999923, 6, 10]\n",
    "\n",
    "# Just checking out Y = mX + c (m = 1, c = 0 => Y = X)\n",
    "x = range(0, 100, 1)\n",
    "y = range(0, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, edgecolors=(0, 0, 0))\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "      layers.Dense(1, use_bias=True, input_shape=(1,))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.01, beta_1=0.9, beta_2=0.99, epsilon=1e-05, amsgrad=False,\n",
    "    name='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae','mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A mechanism that stops training if the validation loss is not improving for more than n_idle_epochs.\n",
    "n_idle_epochs = 100\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=n_idle_epochs, min_delta=0.01)\n",
    "# Creating a custom callback to print the log after a certain number of epochs\n",
    "class NEPOCHLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,per_epoch=100):\n",
    "        '''\n",
    "        display: Number of batches to wait before outputting loss\n",
    "        '''\n",
    "        self.seen = 0\n",
    "        self.per_epoch = per_epoch\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "      if epoch % self.per_epoch == 0:\n",
    "        print('Epoch {}, loss {:.2f}, mae {:.2f}, mse {:.2f}'\\\n",
    "              .format(epoch, logs['loss'], logs['mae'], logs['mse']))\n",
    "\n",
    "log_display = NEPOCHLogger(per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED MLOPS STUFF HERE FOR HYPERPARAMS AND RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2000\n",
    "history = model.fit(\n",
    "  X_train, y_train, batch_size=32,\n",
    "  epochs=n_epochs, verbose=0, callbacks=[earlyStopping, log_display])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(predictions, y_test, edgecolors=(0, 0, 0))\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "lims = [0, 10]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([10,20,30,200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"linear.h5\") # for HDF5 format\n",
    "\n",
    "# For converting to ONNX\n",
    "tf.saved_model.save(model, \"./models/saved_models/linear_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===============================================================================================================================================\")\n",
    "print(\"\\n\\n>>> IMPORTANT: CONVERT TO ONNX MODEL FORMAT\\n\\n$ python3 -m tf2onnx.convert --saved-model 'models/saved_models/linear_model' --output 'models/onnx_models/linear.onnx'\\n\\n\")\n",
    "print(\"===============================================================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "session = onnxruntime.InferenceSession(\"./models/onnx_models/linear.onnx\", providers=['CPUExecutionProvider'])\n",
    "\n",
    "\n",
    "xrange = np.arange(1000, 1025, 1)\n",
    "x_live = np.array([xrange[i:i+1] for i in range(0,len(xrange),1)]).astype(np.float32)\n",
    "print(x_live)\n",
    "\n",
    "ortvalue = onnxruntime.OrtValue.ortvalue_from_numpy(x_live)\n",
    "ortvalue.device_name()  # 'cpu'\n",
    "ortvalue.shape()        # shape of the numpy array X\n",
    "ortvalue.data_type()    # 'tensor(float)'\n",
    "ortvalue.is_tensor()    # 'True'\n",
    "\n",
    "input_name = session.get_inputs()[0].name\n",
    "print(input_name)\n",
    "\n",
    "output_name = session.get_outputs()[0].name\n",
    "print(output_name)\n",
    "\n",
    "np.array_equal(ortvalue.numpy(), x_live)  # 'True'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = session.run(None, {input_name: ortvalue})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running model inferencing on Triton model server\n",
    "\n",
    "`$ docker pull nvcr.io/nvidia/tritonserver:22.03-py3`\n",
    "\n",
    "`$ docker run --rm -p8000:8000 -p8001:8001 -p8002:8002 -v $(pwd)/triton_model_repository:/models nvcr.io/nvidia/tritonserver:22.03-py3 tritonserver --model-repository=/models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tritonclient.http as httpclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input0_data = np.array([[1231231]], dtype=np.float32)\n",
    "#input0_data = input0_data.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [httpclient.InferInput('dense_input', [1, 1], \"FP32\")]\n",
    "inputs[0].set_data_from_numpy(input0_data, binary_data=False)\n",
    "\n",
    "outputs = []\n",
    "outputs.append(httpclient.InferRequestedOutput('dense', binary_data=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triton_client = httpclient.InferenceServerClient(url=\"0.0.0.0:8000\")\n",
    "\n",
    "results = triton_client.infer(\"linear_model_onnx\", inputs, outputs=outputs)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.get_response()[\"outputs\"][0][\"data\"]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
